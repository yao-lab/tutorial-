{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib  inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import torch\n",
    "import time\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "#import basic_cnn\n",
    "from collections import OrderedDict #if import basic_cnn, this line can be dropped\n",
    "from utils import AverageMeter, accuracy, get_margin\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_tight_frame = torch.empty(18,3,3,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_tight_frame[0,:,:]=torch.tensor([[1,2,1],[2,4,2],[1,2,1]],dtype=torch.float)/16\n",
    "geom_tight_frame[1,:,:]=torch.tensor([[1,0,-1],[2,0,-2],[1,0,-1]],dtype=torch.float)/16\n",
    "geom_tight_frame[2,:,:]=torch.tensor([[1,2,1],[0,0,0],[-1,-2,-1]],dtype=torch.float)/16\n",
    "geom_tight_frame[3,:,:]=torch.tensor([[1,1,0],[1,0,-1],[0,-1,-1]],dtype=torch.float)*np.sqrt(2)/16\n",
    "geom_tight_frame[4,:,:]=torch.tensor([[0,1,1],[-1,0,1],[-1,-1,0]],dtype=torch.float)*np.sqrt(2)/16\n",
    "geom_tight_frame[5,:,:]=torch.tensor([[1,0,-1],[0,0,0],[-1,0,1]],dtype=torch.float)*np.sqrt(7)/24\n",
    "geom_tight_frame[6,:,:]=torch.tensor([[-1,2,-1],[-2,4,-2],[-1,2,-1]],dtype=torch.float)/48\n",
    "geom_tight_frame[7,:,:]=torch.tensor([[-1,-2,-1],[2,4,2],[-1,-2,-1]],dtype=torch.float)/48\n",
    "geom_tight_frame[8,:,:]=torch.tensor([[0,0,-1],[0,2,0],[-1,0,0]],dtype=torch.float)/12\n",
    "geom_tight_frame[9,:,:]=torch.tensor([[-1,0,0],[0,2,0],[0,0,-1]],dtype=torch.float)/12\n",
    "geom_tight_frame[10,:,:]=torch.tensor([[0,1,0],[-1,0,-1],[0,1,0]],dtype=torch.float)*np.sqrt(2)/12\n",
    "geom_tight_frame[11,:,:]=torch.tensor([[-1,0,1],[2,0,-2],[-1,0,1]],dtype=torch.float)*np.sqrt(2)/16\n",
    "geom_tight_frame[12,:,:]=torch.tensor([[-1,2,-1],[0,0,0],[1,-2,1]],dtype=torch.float)*np.sqrt(2)/16\n",
    "geom_tight_frame[13,:,:]=torch.tensor([[1,-2,1],[-2,4,-2],[1,-2,1]],dtype=torch.float)/48\n",
    "geom_tight_frame[14,:,:]=torch.tensor([[0,0,0],[-1,2,-1],[0,0,0]],dtype=torch.float)*np.sqrt(2)/12\n",
    "geom_tight_frame[15,:,:]=torch.tensor([[-1,2,-1],[0,0,0],[-1,2,-1]],dtype=torch.float)*np.sqrt(2)/24\n",
    "geom_tight_frame[16,:,:]=torch.tensor([[0,-1,0],[0,2,0],[0,-1,0]],dtype=torch.float)*np.sqrt(2)/12\n",
    "geom_tight_frame[17,:,:]=torch.tensor([[-1,0,-1],[2,0,2],[-1,0,-1]],dtype=torch.float)*np.sqrt(2)/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tight frame tensor:  torch.Size([18, 1, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "geom_tight_frame = geom_tight_frame.reshape([18,1,1,3,3])\n",
    "print('tight frame tensor: ',geom_tight_frame.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0625,  0.1250,  0.0625],\n",
      "        [ 0.1250,  0.2500,  0.1250],\n",
      "        [ 0.0625,  0.1250,  0.0625]])\n"
     ]
    }
   ],
   "source": [
    "print(geom_tight_frame[0,0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to construct a 5-layer CNN where each convolutional layer is a linear combination of geometric tight frames above?\n",
    "class CNN_frame(nn.Module):\n",
    "    def __init__(self, channels, filters, output_size, with_bn=True):\n",
    "        super(CNN_frame, self).__init__()\n",
    "        self.with_bn = with_bn\n",
    "        self.features = self._make_layers(channels)\n",
    "        self.classifier = nn.Linear(channels, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, channels):\n",
    "        layers = []\n",
    "        in_channels = 1 #in_channels = 3\n",
    "        for i in range(1): #for i in range(5):\n",
    "            if i == 0:\n",
    "                if self.with_bn:\n",
    "                    layers += [('conv%dB' % i, nn.Conv3d(in_channels, filters, [1,3,3], stride=2, padding=[0,1,1])),\n",
    "                               ('conv%dW' % i, nn.Conv3d(filters, channels, [3,1,1], stride=1, padding=0)),\n",
    "                               ('bn%d' % i, nn.BatchNorm2d(channels)),\n",
    "                               ('relu%d' % i, nn.ReLU(inplace=True))]\n",
    "                else:\n",
    "                    layers += [('conv%dB' % i, nn.Conv3d(in_channels, filters, [1,3,3], stride=2, padding=[0,1,1])),\n",
    "                               ('conv%dW' % i, nn.Conv3d(filters, channels, [3,1,1], stride=1, padding=0)),#('conv%d' % i, nn.Conv2d(in_channels, channels, 3, 2, 1)),\n",
    "                               ('relu%d' % i, nn.ReLU(inplace=True))]\n",
    "            else:\n",
    "                if self.with_bn:\n",
    "                    layers += [('conv%dB' % i, nn.Conv3d(in_channels, filters, [1,3,3], stride=2, padding=[0,1,1])),\n",
    "                               ('conv%dW' % i, nn.Conv3d(filters, channels, [3,1,1], stride=1, padding=0)), #('conv%d' % i, nn.Conv2d(channels, channels, 3, 2, 1)),\n",
    "                               ('bn%d' % i, nn.BatchNorm2d(channels)),\n",
    "                               ('relu%d' % i, nn.ReLU(inplace=True))]\n",
    "                else:\n",
    "                    layers += [('conv%dB' % i, nn.Conv3d(in_channels, filters, [1,3,3], stride=2, padding=[0,1,1])),\n",
    "                               ('conv%dW' % i, nn.Conv3d(filters, channels, [3,1,1], stride=1, padding=0)),#('conv%d' % i, nn.Conv2d(channels, channels, 3, 2, 1)),\n",
    "                               ('relu%d' % i, nn.ReLU(inplace=True))]\n",
    "        return nn.Sequential(OrderedDict(layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with Cross-Entropy Loss\n",
    "def train_model(model, criterion, optimizer, log_saver, num_epochs=100, margin_dist_ind=[]):\n",
    "    since = time.time()\n",
    "    steps = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        margin = []\n",
    "\n",
    "        for phase in ['train', 'test']:\n",
    "\n",
    "            loss_meter = AverageMeter()\n",
    "            acc_meter = AverageMeter()\n",
    "\n",
    "            if phase == 'train':\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            for i, data in enumerate(loaders[phase]):\n",
    "                inputs, labels = data\n",
    "                if use_gpu:\n",
    "                    inputs = inputs.cuda()\n",
    "                    labels = labels.cuda()\n",
    "                inputs = Variable(inputs)\n",
    "                labels = Variable(labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # The inputs are of size [batch_size,in_channels,H,W], and is changed to [batch_size,1,in_channels,H,W]\n",
    "                inputs = inputs.unsqueeze(1)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    steps += 1\n",
    "                    margin = np.append(margin, get_margin(outputs, labels))\n",
    "\n",
    "                loss_meter.update(loss.data.item(), outputs.size(0))\n",
    "                acc_meter.update(accuracy(outputs.data, labels.data)[-1].item(), outputs.size(0))\n",
    "\n",
    "            epoch_loss = loss_meter.avg\n",
    "            epoch_error = 1 - acc_meter.avg / 100\n",
    "\n",
    "            if phase == 'train':\n",
    "\n",
    "                log_saver['train_loss'].append(epoch_loss)\n",
    "                log_saver['train_error'].append(epoch_error)\n",
    "                log_saver['margin'].append(min(margin))\n",
    "                #log_saver['margin'].append(margin)\n",
    "                ww = 1\n",
    "                for i in range(6):\n",
    "                    if i <= 4:\n",
    "                        size = eval('model.features.conv%d.weight.size()' % i)\n",
    "                        # here to compute the F norm between each CNN layer\n",
    "                        #w_norm = eval('model.features.conv%d.weight.view(size[0],-1).pow(2).sum(1).mean().data.item()' % i)\n",
    "                        #model.features.conv0.weight*model.features.bn0.weight[:,None,None,None]/(model.features.bn0.running_var.sqrt()[:,None,None,None]+1e-5)\n",
    "                        scaled_w = eval('model.features.conv%d.weight*model.features.bn%d.weight[:,None,None,None]/(model.features.bn%d.running_var.sqrt()[:,None,None,None]+1e-5)' % (i,i,i))\n",
    "                        w_norm = scaled_w.view(size[0],-1).pow(2).sum().sqrt().data.item()\n",
    "\n",
    "                        log_saver['w%d' % i].append(w_norm)\n",
    "                    else:\n",
    "                        w_norm = model.classifier.weight.norm(2).data.item()\n",
    "                        log_saver['w_fc'].append(w_norm)\n",
    "                    ww *= w_norm\n",
    "                log_saver['normalised_margin'].append(log_saver['margin'][-1] / ww)\n",
    "                if epoch in margin_dist_ind: \n",
    "                    log_saver['normalized_margin_dist'].append(margin/ww)\n",
    "                    print('Normalized Margin Distribution saved.')\n",
    "\n",
    "            elif phase == 'test':\n",
    "\n",
    "                log_saver['test_loss'].append(epoch_loss)\n",
    "                log_saver['test_error'].append(epoch_error)\n",
    "\n",
    "            print('{} Loss: {:.4f} Error: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_error), end=' ' if phase == 'train' else '\\n')\n",
    "            if phase == 'train':\n",
    "                print('w4_norm: {:.4f} Margin: {:.4f} Norm_margin: {:.4f}'.format(log_saver['w4'][-1],\n",
    "                                                                                  log_saver['margin'][-1],\n",
    "                                                                                  log_saver['normalised_margin'][-1]))\n",
    "\n",
    "        if epoch % 30 == 0 or epoch == num_epochs - 1:\n",
    "            print('Saving..')\n",
    "            state = {\n",
    "                'net': model,\n",
    "                'epoch': epoch,\n",
    "                'log': log_saver\n",
    "            }\n",
    "\n",
    "            if not os.path.isdir('checkpoint_CNN'):\n",
    "                os.mkdir('checkpoint_CNN')\n",
    "            torch.save(state, './checkpoint_CNN/ckpt_epoch_{}.t7'.format(epoch))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return model, log_saver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './'\n",
    "lr = 0.01\n",
    "BATCH_SIZE = 100\n",
    "weight_decay = 0.\n",
    "\n",
    "img_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize(\n",
    "                                         (0.4914, 0.4822, 0.4465),\n",
    "                                         (0.2023, 0.1994, 0.2010))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "training data size: 50000\n",
      "testing data size: 10000\n"
     ]
    }
   ],
   "source": [
    "training_dataset = datasets.CIFAR10(root, train=True, transform=img_transforms, download=True)\n",
    "training_loader = DataLoader(training_dataset, BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "\n",
    "testing_dataset = datasets.CIFAR10(root, train=False, transform=img_transforms)\n",
    "testing_loader = DataLoader(testing_dataset, BATCH_SIZE, shuffle=False, pin_memory=True)\n",
    "\n",
    "loaders = {'train': training_loader, 'test': testing_loader}\n",
    "\n",
    "print('training data size:',len(training_dataset))\n",
    "print('testing data size:',len(testing_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: torch.Size([100, 3, 32, 32])\n",
      "input size changed: torch.Size([100, 1, 3, 32, 32])\n",
      "tight frame tensor:  torch.Size([18, 1, 1, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "phase='test'\n",
    "for i, data in enumerate(loaders[phase]):\n",
    "    inputs, labels = data\n",
    "    if use_gpu:\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "    inputs = Variable(inputs)\n",
    "    labels = Variable(labels)\n",
    "\n",
    "print('input size:',inputs.size())\n",
    "inputs1 = inputs.unsqueeze(1)\n",
    "print('input size changed:',inputs1.size())\n",
    "geom_tight_frame = geom_tight_frame.unsqueeze(1)\n",
    "print('tight frame tensor: ',geom_tight_frame.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number-of-parameters: [1530]\n",
      "All parameter_name: features.conv0B.weight\n",
      "All parameter_name: features.conv0B.bias\n",
      "All parameter_name: features.conv0W.weight\n",
      "All parameter_name: features.conv0W.bias\n",
      "All parameter_name: features.bn0.weight\n",
      "All parameter_name: features.bn0.bias\n",
      "All parameter_name: features.bn0.running_mean\n",
      "All parameter_name: features.bn0.running_var\n",
      "All parameter_name: classifier.weight\n",
      "All parameter_name: classifier.bias\n",
      "Gradient updated parameter_name: features.conv0B.weight\n",
      "Gradient updated parameter_name: features.conv0B.bias\n",
      "Gradient updated parameter_name: features.conv0W.weight\n",
      "Gradient updated parameter_name: features.conv0W.bias\n",
      "Gradient updated parameter_name: features.bn0.weight\n",
      "Gradient updated parameter_name: features.bn0.bias\n",
      "Gradient updated parameter_name: classifier.weight\n",
      "Gradient updated parameter_name: classifier.bias\n"
     ]
    }
   ],
   "source": [
    "log = {'num_params': [],\n",
    "       'train_loss': [],\n",
    "       'train_error': [],\n",
    "       'test_loss': [],\n",
    "       'test_error': [],\n",
    "       'w0': [], 'w1': [], 'w2': [],\n",
    "       'w3': [], 'w4': [], 'w_fc': [],\n",
    "       'margin': [], 'normalised_margin': []}\n",
    "\n",
    "# %% run the model\n",
    "num_epochs = 100\n",
    "channels = 20\n",
    "filters = 18\n",
    "outputs = 10\n",
    "# here use with_bn to control batch normalisation\n",
    "model = CNN_frame(channels, filters, outputs, with_bn=True)\n",
    "\n",
    "number_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "log['num_params'].append(number_params)\n",
    "\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "\n",
    "print('number-of-parameters:',log['num_params'])\n",
    "        \n",
    "for name1, param1 in model.state_dict().items():\n",
    "    print('All parameter_name:',name1)\n",
    "    \n",
    "\n",
    "for name, param in model.named_parameters(): #for name, param in model.state_dict().items():\n",
    "    if param.requires_grad:\n",
    "        print('Gradient updated parameter_name:',name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/usr/local/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2910\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-052395feec02>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    eval('model.features.conv%dB.weight.data = geom_tight_frame' % 0)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    model.features.conv0B.weight.data = geom_tight_frame\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "eval('model.features.conv%dB.weight.data = geom_tight_frame' % 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Basis size: torch.Size([18, 1, 1, 3, 3])\n",
      "\n",
      " Weight size: torch.Size([20, 18, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print('\\n Basis size:', model.features.conv0B.weight.size())\n",
    "print('\\n Weight size:', model.features.conv0W.weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000, -0.1179,  0.0000],\n",
      "        [ 0.0000,  0.2357,  0.0000],\n",
      "        [ 0.0000, -0.1179,  0.0000]])\n",
      "Update param:  tensor([[ 0.0809,  0.1136, -0.0007],\n",
      "        [-0.1312,  0.1008, -0.0868],\n",
      "        [ 0.0713, -0.0295, -0.1310],\n",
      "        [-0.0685,  0.0946,  0.1093],\n",
      "        [-0.1068, -0.0426,  0.1303],\n",
      "        [-0.1117,  0.0182, -0.0943],\n",
      "        [-0.0957,  0.1203, -0.1233],\n",
      "        [-0.0409, -0.0221,  0.1302],\n",
      "        [ 0.0322,  0.0251,  0.0532],\n",
      "        [-0.0153,  0.0702,  0.0986],\n",
      "        [ 0.0910,  0.0878, -0.0403],\n",
      "        [ 0.0624, -0.0884, -0.1307],\n",
      "        [-0.0916, -0.1053,  0.0319],\n",
      "        [ 0.1359,  0.0243,  0.0081],\n",
      "        [-0.1241,  0.0882, -0.0490],\n",
      "        [-0.0197,  0.0839, -0.1073],\n",
      "        [ 0.0778,  0.0890, -0.1154],\n",
      "        [-0.0541, -0.0547,  0.0075]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.features.conv0B.weight.data = geom_tight_frame\n",
    "model.features.conv0B.weight.requires_grad = False\n",
    "model.features.conv0B.bias.data = torch.zeros([18],dtype=torch.float)\n",
    "model.features.conv0B.bias.requires_grad = False\n",
    "\n",
    "#print('bias size:', model.features.conv0B.bias.data.size())\n",
    "\n",
    "print(model.features.conv0B.weight[16,0,0,:,:])\n",
    "print('Update param: ',model.features.conv0W.weight[0,:,:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number-of-parameters: [1530]\n",
      "All parameter_name: features.conv0B.weight\n",
      "All parameter_name: features.conv0B.bias\n",
      "All parameter_name: features.conv0W.weight\n",
      "All parameter_name: features.conv0W.bias\n",
      "All parameter_name: features.bn0.weight\n",
      "All parameter_name: features.bn0.bias\n",
      "All parameter_name: features.bn0.running_mean\n",
      "All parameter_name: features.bn0.running_var\n",
      "All parameter_name: classifier.weight\n",
      "All parameter_name: classifier.bias\n",
      "Gradient updated parameter_name: features.conv0W.weight\n",
      "Gradient updated parameter_name: features.conv0W.bias\n",
      "Gradient updated parameter_name: features.bn0.weight\n",
      "Gradient updated parameter_name: features.bn0.bias\n",
      "Gradient updated parameter_name: classifier.weight\n",
      "Gradient updated parameter_name: classifier.bias\n"
     ]
    }
   ],
   "source": [
    "print('number-of-parameters:',log['num_params'])\n",
    "        \n",
    "for name1, param1 in model.state_dict().items():\n",
    "    print('All parameter_name:',name1)\n",
    "    \n",
    "\n",
    "for name, param in model.named_parameters(): #for name, param in model.state_dict().items():\n",
    "    if param.requires_grad:\n",
    "        print('Gradient updated parameter_name:',name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizing a parameter that doesn't require gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-1a1b26a404f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, momentum, dampening, weight_decay, nesterov)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdampening\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nesterov momentum requires a momentum and zero dampening\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/tensorflow/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36madd_param_group\u001b[0;34m(self, param_group)\u001b[0m\n\u001b[1;32m    191\u001b[0m                                 \"but one of the params is \" + torch.typename(param))\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimizing a parameter that doesn't require gradients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"can't optimize a non-leaf Tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: optimizing a parameter that doesn't require gradients"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "model, log = train_model(model, criterion, optimizer, log, num_epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
